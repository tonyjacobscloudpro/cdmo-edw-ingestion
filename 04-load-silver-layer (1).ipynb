{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "676d7eaf-e1ff-4662-9929-8578598ec0d4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "pip install necessary packages"
    }
   },
   "outputs": [],
   "source": [
    "pip install azure-storage-blob azure-storage-file-datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc48cbb3-301b-438d-96c3-ac839f8a5d15",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Merge bronze into silver delta tables"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Attempting to read metadata file from wasbs://config@cdmo.blob.core.windows.net/metadata_config_20250130.csv...\nüìå Filtered metadata for 'Silver' layer: 5 entries found.\nüîÑ Processing wasbs://01-bronze@cdmo.blob.core.windows.net/customerfeedback/ ‚ûù wasbs://02-silver@cdmo.blob.core.windows.net/customerfeedback_transformed/\n‚úÖ Silver layer transformations applied successfully.\n‚ö†Ô∏è Target path wasbs://02-silver@cdmo.blob.core.windows.net/customerfeedback_transformed/ does not exist. Writing as new table.\nüîÑ Processing wasbs://01-bronze@cdmo.blob.core.windows.net/manufacturebatch/ ‚ûù wasbs://02-silver@cdmo.blob.core.windows.net/manufacturebatch_transformed/\n‚úÖ Silver layer transformations applied successfully.\n‚ö†Ô∏è Target path wasbs://02-silver@cdmo.blob.core.windows.net/manufacturebatch_transformed/ does not exist. Writing as new table.\nüîÑ Processing wasbs://01-bronze@cdmo.blob.core.windows.net/productformula/ ‚ûù wasbs://02-silver@cdmo.blob.core.windows.net/productformula_transformed/\n‚úÖ Silver layer transformations applied successfully.\n‚ö†Ô∏è Target path wasbs://02-silver@cdmo.blob.core.windows.net/productformula_transformed/ does not exist. Writing as new table.\nüîÑ Processing wasbs://01-bronze@cdmo.blob.core.windows.net/sales/ ‚ûù wasbs://02-silver@cdmo.blob.core.windows.net/sales_transformed/\n‚úÖ Silver layer transformations applied successfully.\n‚ö†Ô∏è Target path wasbs://02-silver@cdmo.blob.core.windows.net/sales_transformed/ does not exist. Writing as new table.\nüîÑ Processing wasbs://01-bronze@cdmo.blob.core.windows.net/supplier/ ‚ûù wasbs://02-silver@cdmo.blob.core.windows.net/supplier_transformed/\n‚úÖ Silver layer transformations applied successfully.\n‚ö†Ô∏è Target path wasbs://02-silver@cdmo.blob.core.windows.net/supplier_transformed/ does not exist. Writing as new table.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_timestamp, trim, input_file_name\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 1. SPARK CONFIGURATION & AZURE STORAGE AUTHENTICATION\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "# Azure Storage account details (using SAS Token)\n",
    "STORAGE_ACCOUNT_NAME = \"cdmo\"\n",
    "SAS_TOKEN = \"sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2025-02-01T13:22:40Z&st=2025-01-31T05:22:40Z&spr=https&sig=eNjMZTrl03xT4e2cf5nA2fmHglRbbQaFYgTnqWaECF4%3D\"  # Replace with your SAS token\n",
    "CONTAINER_NAME = \"config\"\n",
    "METADATA_FILE_NAME = \"metadata_config_20250130.csv\"\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SilverLayerProcessing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configure Spark to use SAS Token for each relevant container\n",
    "containers = [\"01-bronze\", \"02-silver\", \"config\"]\n",
    "for container in containers:\n",
    "    spark.conf.set(f\"fs.azure.sas.{container}.{STORAGE_ACCOUNT_NAME}.blob.core.windows.net\", SAS_TOKEN)\n",
    "\n",
    "# Initialize BlobServiceClient using SAS Token\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=f\"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net\",\n",
    "    credential=SAS_TOKEN\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 2. LOAD METADATA FILE FROM BLOB STORAGE (wasbs://)\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "def load_metadata():\n",
    "    \"\"\"\n",
    "    Loads the metadata configuration file from Azure Blob Storage (wasbs://)\n",
    "    and filters datasets for the 'Silver' processing layer.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing metadata configurations.\n",
    "    \"\"\"\n",
    "    metadata_path = f\"wasbs://{CONTAINER_NAME}@{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{METADATA_FILE_NAME}\"\n",
    "\n",
    "    try:\n",
    "        print(f\"üîÑ Attempting to read metadata file from {metadata_path}...\")\n",
    "        metadata_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(metadata_path)\n",
    "\n",
    "        # Fill missing values to avoid NoneType errors\n",
    "        metadata_df = metadata_df.fillna(\"\")\n",
    "\n",
    "        # Convert DataFrame to a list of dictionaries\n",
    "        metadata_list = [row.asDict() for row in metadata_df.collect()]\n",
    "\n",
    "        # Filter for 'silver' layer datasets\n",
    "        metadata_list = [\n",
    "            {\n",
    "                \"SourceContainer\": row.get(\"SourceContainer\", \"\"),\n",
    "                \"SourcePath\": row.get(\"SourcePath\", \"\"),\n",
    "                \"SourceFormat\": row.get(\"SourceFormat\", \"\"),\n",
    "                \"TargetContainer\": row.get(\"TargetContainer\", \"\"),\n",
    "                \"TargetPath\": row.get(\"TargetPath\", \"\"),\n",
    "                \"TargetFormat\": row.get(\"TargetFormat\", \"\"),\n",
    "                \"UniqueKey\": row.get(\"UniqueKey\", None),\n",
    "                \"AddTimestamp\": row.get(\"AddTimestamp\", \"false\").lower() == \"true\",  # Default to False if missing\n",
    "            }\n",
    "            for row in metadata_list if row.get(\"Layer\", \"\").strip().lower() == \"silver\"\n",
    "        ]\n",
    "\n",
    "        print(f\"üìå Filtered metadata for 'Silver' layer: {len(metadata_list)} entries found.\")\n",
    "        return metadata_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading metadata file: {e}\")\n",
    "        raise\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 3. APPLY TRANSFORMATIONS SPECIFIC TO THE SILVER LAYER\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "def transform_silver_layer(source_df):\n",
    "    \"\"\"\n",
    "    Applies transformations for Silver Layer, such as trimming string columns and \n",
    "    adding a processed timestamp.\n",
    "\n",
    "    Args:\n",
    "        source_df (DataFrame): Source DataFrame to be transformed.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Transformed DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Trim all string columns\n",
    "        string_cols = [col_name for col_name, dtype in source_df.dtypes if dtype == \"string\"]\n",
    "        for col_name in string_cols:\n",
    "            source_df = source_df.withColumn(col_name, trim(source_df[col_name]))\n",
    "\n",
    "        # Add timestamp column\n",
    "        source_df = source_df.withColumn(\"ProcessedTimestamp\", current_timestamp())\n",
    "\n",
    "        print(\"‚úÖ Silver layer transformations applied successfully.\")\n",
    "        return source_df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during Silver layer transformations: {e}\")\n",
    "        raise\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 4. PERFORM DELTA MERGE INTO SILVER LAYER\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "def merge_into_silver_layer(source_df, target_path, unique_key):\n",
    "    \"\"\"\n",
    "    Merges data into the Silver Layer using Delta format. Updates existing records\n",
    "    and inserts new ones based on the unique key.\n",
    "\n",
    "    Args:\n",
    "        source_df (DataFrame): Transformed DataFrame to merge.\n",
    "        target_path (str): Target Silver Layer Delta table path.\n",
    "        unique_key (str): Column used as the primary key for merging.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if Delta table exists\n",
    "        if spark._jsparkSession.catalog().tableExists(f\"delta.`{target_path}`\"):\n",
    "            target_df = spark.read.format(\"delta\").load(target_path)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Target path {target_path} does not exist. Writing as new table.\")\n",
    "            source_df.write.format(\"delta\").mode(\"overwrite\").save(target_path)\n",
    "            return\n",
    "\n",
    "        # Register DataFrames as temporary views for SQL-based merge\n",
    "        source_df.createOrReplaceTempView(\"source_temp_view\")\n",
    "        target_df.createOrReplaceTempView(\"target_temp_view\")\n",
    "\n",
    "        # Merge query for Delta Lake\n",
    "        merge_query = f\"\"\"\n",
    "        MERGE INTO delta.`{target_path}` AS target\n",
    "        USING source_temp_view AS source\n",
    "        ON target.{unique_key} = source.{unique_key}\n",
    "        WHEN MATCHED THEN UPDATE SET *\n",
    "        WHEN NOT MATCHED THEN INSERT *\n",
    "        \"\"\"\n",
    "        spark.sql(merge_query)\n",
    "\n",
    "        print(f\"‚úÖ Data successfully merged into Silver Layer at {target_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during Delta Merge: {e}\")\n",
    "        raise\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 5. PROCESS DATA BASED ON METADATA CONFIGURATION\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "def process_data(metadata_list):\n",
    "    \"\"\"\n",
    "    Reads data from the Bronze layer, applies Silver layer transformations,\n",
    "    and merges it into the Silver layer.\n",
    "\n",
    "    Args:\n",
    "        metadata_list (list): List of metadata configurations.\n",
    "    \"\"\"\n",
    "    for metadata in metadata_list:\n",
    "        try:\n",
    "            # Extract metadata details\n",
    "            source_container = metadata[\"SourceContainer\"]\n",
    "            source_path = metadata[\"SourcePath\"]\n",
    "            source_format = metadata[\"SourceFormat\"]\n",
    "            target_container = metadata[\"TargetContainer\"]\n",
    "            target_path = metadata[\"TargetPath\"]\n",
    "            unique_key = metadata.get(\"UniqueKey\")\n",
    "\n",
    "            # Validate required fields\n",
    "            if not all([source_container, source_path, source_format, target_container, target_path, unique_key]):\n",
    "                print(f\"‚ö†Ô∏è Skipping entry due to missing fields: {metadata}\")\n",
    "                continue\n",
    "\n",
    "            # Construct full paths\n",
    "            source_path_wasbs = f\"wasbs://{source_container}@{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{source_path}\"\n",
    "            target_path_wasbs = f\"wasbs://{target_container}@{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{target_path}\"\n",
    "\n",
    "            print(f\"üîÑ Processing {source_path_wasbs} ‚ûù {target_path_wasbs}\")\n",
    "\n",
    "            # Read source data in Delta format\n",
    "            source_df = spark.read.format(\"delta\").load(source_path_wasbs)\n",
    "\n",
    "            # Apply Silver Layer transformations\n",
    "            silver_df = transform_silver_layer(source_df)\n",
    "\n",
    "            # Perform Delta Merge\n",
    "            merge_into_silver_layer(silver_df, target_path_wasbs, unique_key)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing data for Source Path '{metadata.get('SourcePath', 'Unknown')}': {e}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 6. MAIN EXECUTION: LOAD METADATA & PROCESS DATA\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    metadata_list = load_metadata()\n",
    "    process_data(metadata_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b877248-d3ef-42a4-93fa-b0da961f4b2f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Validation 1"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Found 5 tables in the container: {'customerfeedback_transformed', 'supplier_transformed', 'sales_transformed', 'manufacturebatch_transformed', 'productformula_transformed'}\nüîç Validating table: customerfeedback_transformed at wasbs://02-silver@cdmo.blob.core.windows.net/customerfeedback_transformed/\n‚úÖ Table: customerfeedback_transformed, Record Count: 100\nüîç Validating table: supplier_transformed at wasbs://02-silver@cdmo.blob.core.windows.net/supplier_transformed/\n‚úÖ Table: supplier_transformed, Record Count: 40\nüîç Validating table: sales_transformed at wasbs://02-silver@cdmo.blob.core.windows.net/sales_transformed/\n‚úÖ Table: sales_transformed, Record Count: 100\nüîç Validating table: manufacturebatch_transformed at wasbs://02-silver@cdmo.blob.core.windows.net/manufacturebatch_transformed/\n‚úÖ Table: manufacturebatch_transformed, Record Count: 100\nüîç Validating table: productformula_transformed at wasbs://02-silver@cdmo.blob.core.windows.net/productformula_transformed/\n‚úÖ Table: productformula_transformed, Record Count: 40\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 1. SPARK CONFIGURATION & AZURE STORAGE AUTHENTICATION\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "# Define Azure Storage account details (Using SAS Token)\n",
    "STORAGE_ACCOUNT_NAME = \"cdmo\"  # Replace with actual storage account name\n",
    "SAS_TOKEN = \"sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2025-02-01T13:22:40Z&st=2025-01-31T05:22:40Z&spr=https&sig=eNjMZTrl03xT4e2cf5nA2fmHglRbbQaFYgTnqWaECF4%3D\"   # Replace with your SAS token\n",
    "CONTAINER_NAME = \"02-silver\"  # Target container where Silver tables are stored\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SilverLayerValidation\").getOrCreate()\n",
    "\n",
    "# Configure Spark to use the SAS Token for authentication\n",
    "spark.conf.set(f\"fs.azure.sas.{CONTAINER_NAME}.{STORAGE_ACCOUNT_NAME}.blob.core.windows.net\", SAS_TOKEN)\n",
    "\n",
    "# Initialize BlobServiceClient to list tables dynamically\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=f\"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net\",\n",
    "    credential=SAS_TOKEN\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 2. LIST AND VALIDATE TABLES IN THE 02-SILVER CONTAINER\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "def list_tables(container_name):\n",
    "    \"\"\"\n",
    "    Retrieves a list of all directories (tables) from the specified container.\n",
    "\n",
    "    Args:\n",
    "        container_name (str): The Azure Blob Storage container name.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of detected table names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        container_client = blob_service_client.get_container_client(container_name)\n",
    "        blobs = container_client.list_blobs()\n",
    "\n",
    "        # Extract unique table names (assuming folders as table names)\n",
    "        tables = set(blob.name.split('/')[0] for blob in blobs if '/' in blob.name)\n",
    "\n",
    "        print(f\"üìå Found {len(tables)} tables in the container: {tables}\")\n",
    "        return list(tables)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error listing tables in container '{container_name}': {e}\")\n",
    "        return []\n",
    "\n",
    "def validate_silver_tables(container_name, tables):\n",
    "    \"\"\"\n",
    "    Validates the record count for each table in the Silver layer.\n",
    "\n",
    "    Args:\n",
    "        container_name (str): The Azure Blob Storage container name.\n",
    "        tables (list): A list of table names to validate.\n",
    "    \"\"\"\n",
    "    for table in tables:\n",
    "        # Construct the full wasbs:// path for each table in the Silver layer\n",
    "        table_path = f\"wasbs://{container_name}@{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{table}/\"\n",
    "\n",
    "        print(f\"üîç Validating table: {table} at {table_path}\")\n",
    "\n",
    "        try:\n",
    "            # Attempt to read the table\n",
    "            df = spark.read.format(\"delta\").option(\"mergeSchema\", \"true\").load(table_path)\n",
    "\n",
    "            # Get the count of records\n",
    "            record_count = df.count()\n",
    "\n",
    "            if record_count > 0:\n",
    "                print(f\"‚úÖ Table: {table}, Record Count: {record_count}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Table: {table} exists but is empty.\")\n",
    "\n",
    "        except Exception as read_error:\n",
    "            print(f\"‚ö†Ô∏è Table '{table}' does not exist or is not accessible: {read_error}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 3. MAIN EXECUTION\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tables = list_tables(CONTAINER_NAME)  # Get list of tables dynamically\n",
    "    if tables:\n",
    "        validate_silver_tables(CONTAINER_NAME, tables)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No tables found in the Silver container.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41cc65cd-9bdb-443d-9cd9-b32355151b7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Found 5 tables in the container: {'customerfeedback_transformed', 'supplier_transformed', 'sales_transformed', 'manufacturebatch_transformed', 'productformula_transformed'}\nüîç Validating table: customerfeedback_transformed at wasbs://02-silver@cdmo.blob.core.windows.net/customerfeedback_transformed/\n‚úÖ Table: customerfeedback_transformed, Record Count: 100\nüìä Preview of the first 5 rows in customerfeedback_transformed:\n+---+------------------------------------+------------------------------------+------------------------------------+------+--------+------------+-----------------------------------------------------------------------------------------------------------------+-----------------------+----------------------+\n|id |FeedbackID                          |ProductID                           |CustomerID                          |Rating|Comments|FeedbackDate|Filename                                                                                                         |LoadTimestamp          |ProcessedTimestamp    |\n+---+------------------------------------+------------------------------------+------------------------------------+------+--------+------------+-----------------------------------------------------------------------------------------------------------------+-----------------------+----------------------+\n|0  |823f8ebb-2962-4792-9b65-04f4c4efc4ab|1734248b-a2aa-4550-a0e7-b442b6380fae|04917cdb-a5d9-4b5a-a53d-be1ead775fee|1     |null    |2024-05-14  |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/customerfeedback/customerfeedback_20250130_045331.csv|2025-01-30 05:03:46.845|2025-01-31 05:42:15.12|\n|1  |b8d706ff-db62-4cf7-ab5c-70c30b5182d5|82a3cc22-be81-4387-a969-d007012af821|2ea6d8ac-0b73-4705-bd0d-e7ae80e239ed|1     |null    |2024-06-25  |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/customerfeedback/customerfeedback_20250130_045331.csv|2025-01-30 05:03:46.845|2025-01-31 05:42:15.12|\n|2  |7435f123-6d32-4050-905c-2a1aab21622f|f9c95ae4-4d4e-490d-8c89-1c5f141d8d6f|168ff7d5-a2c7-4c51-a67a-84c2ac22852a|2     |null    |2024-08-06  |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/customerfeedback/customerfeedback_20250130_045331.csv|2025-01-30 05:03:46.845|2025-01-31 05:42:15.12|\n|3  |918832ce-1be7-48be-8257-635908af3b4e|7f12b042-a480-47fd-9d10-6a1d857683d7|45c9f848-5c84-4870-ac5f-f697c9471f62|4     |null    |2025-01-06  |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/customerfeedback/customerfeedback_20250130_045331.csv|2025-01-30 05:03:46.845|2025-01-31 05:42:15.12|\n|4  |cc3bd229-f85f-4992-a135-99b21548b6ee|d3e64104-9e64-4bca-9e1e-8e07a522d046|5f2dfe65-3372-4aa3-a293-bf274dd730af|2     |null    |2024-09-08  |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/customerfeedback/customerfeedback_20250130_045331.csv|2025-01-30 05:03:46.845|2025-01-31 05:42:15.12|\n+---+------------------------------------+------------------------------------+------------------------------------+------+--------+------------+-----------------------------------------------------------------------------------------------------------------+-----------------------+----------------------+\nonly showing top 5 rows\n\nüîç Validating table: supplier_transformed at wasbs://02-silver@cdmo.blob.core.windows.net/supplier_transformed/\n‚úÖ Table: supplier_transformed, Record Count: 40\nüìä Preview of the first 5 rows in supplier_transformed:\n+---+------------------------------------+------------+---------------+---------+------------+-------------------------------------------------------------------------------------------------+-----------------------+-----------------------+\n|id |SupplierID                          |SupplierName|Material       |Cost     |DeliveryDate|Filename                                                                                         |LoadTimestamp          |ProcessedTimestamp     |\n+---+------------------------------------+------------+---------------+---------+------------+-------------------------------------------------------------------------------------------------+-----------------------+-----------------------+\n|0  |2457fee9-132d-47d4-88fd-e04406413c0e|null        |Aloe Vera      |53.149853|2024-11-14  |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/supplier/supplier_20250130_045331.csv|2025-01-30 05:04:24.882|2025-01-31 05:43:01.045|\n|1  |3a5b64fd-fbca-44b7-820a-c50f602a0f6d|null        |Collagen       |92.56125 |2025-01-19  |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/supplier/supplier_20250130_045331.csv|2025-01-30 05:04:24.882|2025-01-31 05:43:01.045|\n|2  |f6598e46-d304-409a-883c-1b5cb653dd10|null        |Aloe Vera      |35.079376|2024-09-12  |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/supplier/supplier_20250130_045331.csv|2025-01-30 05:04:24.882|2025-01-31 05:43:01.045|\n|3  |4fa6f523-fa3b-40bf-a34b-092598e5a2b9|null        |Collagen       |92.13411 |2024-03-21  |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/supplier/supplier_20250130_045331.csv|2025-01-30 05:04:24.882|2025-01-31 05:43:01.045|\n|4  |7d2d14ac-7a44-44b4-91ae-a3fc4be2978b|null        |Hyaluronic Acid|10.346646|2024-09-08  |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/supplier/supplier_20250130_045331.csv|2025-01-30 05:04:24.882|2025-01-31 05:43:01.045|\n+---+------------------------------------+------------+---------------+---------+------------+-------------------------------------------------------------------------------------------------+-----------------------+-----------------------+\nonly showing top 5 rows\n\nüîç Validating table: sales_transformed at wasbs://02-silver@cdmo.blob.core.windows.net/sales_transformed/\n‚úÖ Table: sales_transformed, Record Count: 100\nüìä Preview of the first 5 rows in sales_transformed:\n+---+------------------------------------+------------------------------------+------------------------------------+--------+-----------+----------+-------------------------------------------------------------------------------------------+-----------------------+-----------------------+\n|id |OrderID                             |CustomerID                          |ProductID                           |Quantity|TotalAmount|OrderDate |Filename                                                                                   |LoadTimestamp          |ProcessedTimestamp     |\n+---+------------------------------------+------------------------------------+------------------------------------+--------+-----------+----------+-------------------------------------------------------------------------------------------+-----------------------+-----------------------+\n|0  |24a3c597-b47c-44f3-9ea3-ce61eb4fbb86|8cc26038-7ac2-4794-9926-dd3a564a66a0|4aef150d-abbe-4777-8006-606043a20910|6       |421.44876  |2024-06-22|wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/sales/sales_20250130_045331.csv|2025-01-30 05:04:15.794|2025-01-31 05:42:46.969|\n|1  |3a615482-8a4f-4525-997b-25518915bda1|2249009d-86df-4174-a43a-e7aa349d39d9|b4b7c670-84b1-4190-9007-ccff70bbf977|7       |104.24159  |2025-01-12|wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/sales/sales_20250130_045331.csv|2025-01-30 05:04:15.794|2025-01-31 05:42:46.969|\n|2  |c580a924-00f7-4b14-9042-764aaba00fc4|ae5ac3de-29e0-4402-bd8f-bbfb96a92865|56fc973f-660d-40cd-969e-38ae1ef36a96|7       |297.30954  |2024-07-24|wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/sales/sales_20250130_045331.csv|2025-01-30 05:04:15.794|2025-01-31 05:42:46.969|\n|3  |625e0563-17c1-4d45-96de-d642777ab8a0|cf958a04-c24a-4444-8505-cefbe81fee3f|2d6b3cfe-e847-43de-b522-46df561c457d|3       |360.72583  |2024-02-15|wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/sales/sales_20250130_045331.csv|2025-01-30 05:04:15.794|2025-01-31 05:42:46.969|\n|4  |658bae55-f255-4312-b634-3ba2a9ac7d6c|8b1e9b48-dae0-4ef7-988a-2a80fd0ec5f9|4ed98e1c-de11-4696-ae47-f491fcb5f77d|7       |99.40935   |2024-11-19|wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/sales/sales_20250130_045331.csv|2025-01-30 05:04:15.794|2025-01-31 05:42:46.969|\n+---+------------------------------------+------------------------------------+------------------------------------+--------+-----------+----------+-------------------------------------------------------------------------------------------+-----------------------+-----------------------+\nonly showing top 5 rows\n\nüîç Validating table: manufacturebatch_transformed at wasbs://02-silver@cdmo.blob.core.windows.net/manufacturebatch_transformed/\n‚úÖ Table: manufacturebatch_transformed, Record Count: 100\nüìä Preview of the first 5 rows in manufacturebatch_transformed:\n+---+------------------------------------+------------------------------------+----------+--------+-----------+-----------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------+\n|id |BatchID                             |ProductID                           |BatchDate |Quantity|Status     |Filename                                                                                                         |LoadTimestamp          |ProcessedTimestamp     |\n+---+------------------------------------+------------------------------------+----------+--------+-----------+-----------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------+\n|0  |ca7f56a4-00c7-40d3-8bfe-3685ca6db601|832aaaf3-1c0e-4ee4-9041-a360c35df8a0|2024-08-28|295     |Failed     |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/manufacturebatch/manufacturebatch_20250130_045331.csv|2025-01-30 05:03:57.245|2025-01-31 05:42:25.604|\n|1  |406a93b8-140e-4833-9859-32fdefcd910b|2e075033-d912-4f75-9b8c-29c615eeb057|2024-02-27|205     |In Progress|wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/manufacturebatch/manufacturebatch_20250130_045331.csv|2025-01-30 05:03:57.245|2025-01-31 05:42:25.604|\n|2  |ad3b3640-f7da-4a95-91d0-4ad36d5f8e48|e466811f-7026-4fcd-acae-81b262471226|2024-11-11|917     |Completed  |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/manufacturebatch/manufacturebatch_20250130_045331.csv|2025-01-30 05:03:57.245|2025-01-31 05:42:25.604|\n|3  |ce042c8e-58c9-439d-90d8-1154d224220b|0f93e1cb-0826-41d7-a68b-be6b4c303bc9|2024-11-12|198     |Pending    |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/manufacturebatch/manufacturebatch_20250130_045331.csv|2025-01-30 05:03:57.245|2025-01-31 05:42:25.604|\n|4  |6a7258ba-8398-4877-9d33-c18a17d1a4c4|b3bd3eee-e34b-4215-b3e8-dfab31e9fe05|2024-08-06|303     |Failed     |wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/manufacturebatch/manufacturebatch_20250130_045331.csv|2025-01-30 05:03:57.245|2025-01-31 05:42:25.604|\n+---+------------------------------------+------------------------------------+----------+--------+-----------+-----------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------+\nonly showing top 5 rows\n\nüîç Validating table: productformula_transformed at wasbs://02-silver@cdmo.blob.core.windows.net/productformula_transformed/\n‚úÖ Table: productformula_transformed, Record Count: 40\nüìä Preview of the first 5 rows in productformula_transformed:\n+---+------------------------------------+------------+----------+---------------+----------------------------+----------+-------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------+\n|id |ProductID                           |ProductName |Category  |FormulationType|PrimaryIngredients          |LaunchDate|Filename                                                                                                     |LoadTimestamp          |ProcessedTimestamp     |\n+---+------------------------------------+------------+----------+---------------+----------------------------+----------+-------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------+\n|0  |24a310ab-684e-4c77-a9aa-2ae828c1e544|8 Foundation|Lipstick  |Liquid         |Hyaluronic Acid, Vitamin E  |2024-04-05|wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/productformula/productformula_20250130_045331.csv|2025-01-30 05:04:06.856|2025-01-31 05:42:36.505|\n|1  |2d711bd7-fd4c-4a74-8e3c-a0dff069c652|6 Lipstick  |Lipstick  |Liquid         |Shea Butter, Hyaluronic Acid|2023-05-27|wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/productformula/productformula_20250130_045331.csv|2025-01-30 05:04:06.856|2025-01-31 05:42:36.505|\n|2  |739600ed-69f4-42ae-b91c-f6b2551ae590|1 Lipstick  |Eyeshadow |Cream          |Shea Butter, Collagen       |2023-12-17|wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/productformula/productformula_20250130_045331.csv|2025-01-30 05:04:06.856|2025-01-31 05:42:36.505|\n|3  |f2989b72-33c2-431f-8382-250a23ae28ef|4 Eyeshadow |Foundation|Stick          |Collagen, Collagen          |2024-08-06|wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/productformula/productformula_20250130_045331.csv|2025-01-30 05:04:06.856|2025-01-31 05:42:36.505|\n|4  |a80ef484-6b83-4179-aaf5-88207da63468|1 Blush     |Lipstick  |Liquid         |Collagen, Vitamin E         |2023-08-01|wasbs://00-landing@cdmo.blob.core.windows.net/data/incoming/productformula/productformula_20250130_045331.csv|2025-01-30 05:04:06.856|2025-01-31 05:42:36.505|\n+---+------------------------------------+------------+----------+---------------+----------------------------+----------+-------------------------------------------------------------------------------------------------------------+-----------------------+-----------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 1. SPARK CONFIGURATION & AZURE STORAGE AUTHENTICATION\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "# Define Azure Storage account details (Using SAS Token)\n",
    "STORAGE_ACCOUNT_NAME = \"cdmo\"  # Replace with actual storage account name\n",
    "SAS_TOKEN = \"sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2025-02-01T13:22:40Z&st=2025-01-31T05:22:40Z&spr=https&sig=eNjMZTrl03xT4e2cf5nA2fmHglRbbQaFYgTnqWaECF4%3D\"  # Replace with your SAS token\n",
    "CONTAINER_NAME = \"02-silver\"  # Target container where Silver tables are stored\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SilverLayerValidation\").getOrCreate()\n",
    "\n",
    "# Configure Spark to use the SAS Token for authentication\n",
    "spark.conf.set(f\"fs.azure.sas.{CONTAINER_NAME}.{STORAGE_ACCOUNT_NAME}.blob.core.windows.net\", SAS_TOKEN)\n",
    "\n",
    "# Initialize BlobServiceClient to list tables dynamically\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=f\"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net\",\n",
    "    credential=SAS_TOKEN\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 2. LIST AND VALIDATE TABLES IN THE 02-SILVER CONTAINER\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "def list_tables(container_name):\n",
    "    \"\"\"\n",
    "    Retrieves a list of all directories (tables) from the specified container.\n",
    "\n",
    "    Args:\n",
    "        container_name (str): The Azure Blob Storage container name.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of detected table names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        container_client = blob_service_client.get_container_client(container_name)\n",
    "        blobs = container_client.list_blobs()\n",
    "\n",
    "        # Extract unique table names (assuming folders as table names)\n",
    "        tables = set(blob.name.split('/')[0] for blob in blobs if '/' in blob.name)\n",
    "\n",
    "        print(f\"üìå Found {len(tables)} tables in the container: {tables}\")\n",
    "        return list(tables)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error listing tables in container '{container_name}': {e}\")\n",
    "        return []\n",
    "\n",
    "def validate_silver_tables(container_name, tables):\n",
    "    \"\"\"\n",
    "    Validates the record count and displays the first 5 rows of each table.\n",
    "\n",
    "    Args:\n",
    "        container_name (str): The Azure Blob Storage container name.\n",
    "        tables (list): A list of table names to validate.\n",
    "    \"\"\"\n",
    "    for table in tables:\n",
    "        # Construct the full wasbs:// path for each table in the Silver layer\n",
    "        table_path = f\"wasbs://{container_name}@{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{table}/\"\n",
    "\n",
    "        print(f\"üîç Validating table: {table} at {table_path}\")\n",
    "\n",
    "        try:\n",
    "            # Attempt to read the table\n",
    "            df = spark.read.format(\"delta\").option(\"mergeSchema\", \"true\").load(table_path)\n",
    "\n",
    "            # Get the count of records\n",
    "            record_count = df.count()\n",
    "\n",
    "            if record_count > 0:\n",
    "                print(f\"‚úÖ Table: {table}, Record Count: {record_count}\")\n",
    "\n",
    "                # Display the first 5 rows for validation\n",
    "                print(f\"üìä Preview of the first 5 rows in {table}:\")\n",
    "                df.show(5, truncate=False)\n",
    "\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Table: {table} exists but is empty.\")\n",
    "\n",
    "        except Exception as read_error:\n",
    "            print(f\"‚ö†Ô∏è Table '{table}' does not exist or is not accessible: {read_error}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 3. MAIN EXECUTION\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tables = list_tables(CONTAINER_NAME)  # Get list of tables dynamically\n",
    "    if tables:\n",
    "        validate_silver_tables(CONTAINER_NAME, tables)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No tables found in the Silver container.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04-load-silver-layer",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
