{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84cd264c-0d62-4413-a0cd-834b847129b5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create a date dimension in gold layer"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, sequence\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"DateDimensionLoad\").getOrCreate()\n",
    "\n",
    "# Azure Storage connection details\n",
    "storage_account_name = \"cdmo\"\n",
    "storage_account_key = \"XXXXXXXXXXXXX\"\n",
    "\n",
    "# Set Spark configuration for Azure Blob Storage\n",
    "spark.conf.set(f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\", storage_account_key)\n",
    "\n",
    "# Define the Gold layer container path\n",
    "gold_layer_path = f\"abfss://03-gold@{storage_account_name}.dfs.core.windows.net/date_dimension\"\n",
    "\n",
    "# Create a function to generate the date dimension DataFrame\n",
    "def create_date_dimension(start_date, end_date):\n",
    "    # Generate a sequence of dates between start_date and end_date\n",
    "    date_df = spark.sql(f\"\"\"\n",
    "        SELECT explode(sequence(to_date('{start_date}'), to_date('{end_date}'), interval 1 day)) as date\n",
    "    \"\"\")\n",
    "    \n",
    "# Add additional date-related columns\n",
    "    date_dimension_df = (\n",
    "        date_df.withColumn(\"Year\", expr(\"year(date)\"))\n",
    "               .withColumn(\"Month\", expr(\"month(date)\"))\n",
    "               .withColumn(\"Day\", expr(\"day(date)\"))\n",
    "               .withColumn(\"DayOfWeek\", expr(\"date_format(date, 'EEEE')\"))\n",
    "               .withColumn(\"Quarter\", expr(\"quarter(date)\"))\n",
    "               .withColumn(\"WeekOfYear\", expr(\"weekofyear(date)\"))\n",
    "               .withColumn(\"IsWeekend\", expr(\"case when date_format(date, 'EEEE') IN ('Saturday', 'Sunday') then true else false end\"))\n",
    "               .withColumn(\"IsHoliday\", lit(False))  # Placeholder, update for specific holidays\n",
    "               .withColumn(\"MonthName\", expr(\"date_format(date, 'MMMM')\"))\n",
    "               .withColumn(\"DayOfMonth\", expr(\"dayofmonth(date)\"))\n",
    "               .withColumn(\"DayOfYear\", expr(\"dayofyear(date)\"))\n",
    "    )\n",
    "    return date_dimension_df\n",
    "\n",
    "# Define start and end dates\n",
    "start_date = \"2000-01-01\"  # Replace with your desired start date\n",
    "end_date = \"2099-12-31\"    # Replace with your desired end date\n",
    "\n",
    "# Create the date dimension DataFrame\n",
    "date_dimension_df = create_date_dimension(start_date, end_date)\n",
    "\n",
    "# Write the DataFrame to the Delta table in the Gold layer\n",
    "try:\n",
    "    date_dimension_df.write.format(\"delta\").mode(\"overwrite\").save(gold_layer_path)\n",
    "    print(f\"Date dimension successfully written to: {gold_layer_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to Gold layer: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "661a4b9e-5dde-4aec-9dc1-ca40f7655daa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Validation"
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the date dimension table in the Gold layer\n",
    "gold_layer_path = f\"abfss://03-gold@{storage_account_name}.dfs.core.windows.net/date_dimension\"\n",
    "\n",
    "# Read the Delta table from the Gold layer\n",
    "try:\n",
    "    date_dimension_df = spark.read.format(\"delta\").load(gold_layer_path)\n",
    "    print(f\"Successfully loaded date dimension from: {gold_layer_path}\")\n",
    "    \n",
    "    # Display the first 10 rows of the DataFrame\n",
    "    date_dimension_df.display()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading date dimension: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05-create-dim-date-gold",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
